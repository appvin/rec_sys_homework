{
 "metadata": {
  "name": "",
  "signature": "sha256:cbd49792b08b81461030155ffa14e43e6b7225ee7be4e1be9e298ae9ae7e80df"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import random\n",
      "import pandas as pd\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from scipy.sparse import csr_matrix\n",
      "import logging\n",
      "from gensim import corpora, models, similarities\n",
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.stem.lancaster import LancasterStemmer\n",
      "\n",
      "class item_search:\n",
      "    index=0\n",
      "    dictionary=0\n",
      "    lsi=0\n",
      "    \n",
      "    def __init__(self,itempath):\n",
      "        item_search.items = pd.read_table(itempath, header=None,sep='|')\n",
      "        item_topic=item_search.items[1].str.partition('(')[0]\n",
      "\n",
      "        #\u5c0f\u5199\u5316\uff0c\u53bb\u505c\u7528\u8bcd\uff0c\u53bb\u6807\u70b9\u7b26\u53f7\n",
      "        texts_tokenized = [[word.lower() for word in word_tokenize(document)] for document in item_topic]  \n",
      "        english_stopwords = stopwords.words('english')\n",
      "        texts_filtered_stopwords = [[word for word in document if not word in english_stopwords] for document in texts_tokenized]\n",
      "        english_punctuations = [',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%']\n",
      "        texts_filtered = [[word for word in document if not word in english_punctuations] for document in texts_filtered_stopwords]\n",
      "\n",
      "        #\u8bcd\u5e72\u5316\n",
      "        item_search.st = LancasterStemmer()\n",
      "        texts_stemmed = [[item_search.st.stem(word) for word in docment] for docment in texts_filtered]\n",
      "\n",
      "        #\u53bb\u6389\u8bed\u6599\u5e93\u4e2d\u7684\u4f4e\u9891\u8bcd\n",
      "        all_stems = sum(texts_stemmed)\n",
      "        stems_once = set(stem for stem in set(all_stems) if all_stems.count(stem) == 1)\n",
      "        texts = [[stem for stem in text if stem not in stems_once] for text in texts_stemmed]\n",
      "        texts=texts_stemmed\n",
      "\n",
      "        #gensim\u9884\u5904\u7406\n",
      "        logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
      "        item_search.dictionary = corpora.Dictionary(texts)\n",
      "        corpus = [item_search.dictionary.doc2bow(text) for text in texts]\n",
      "        tfidf = models.TfidfModel(corpus)\n",
      "        corpus_tfidf = tfidf[corpus]\n",
      "\n",
      "        #\u8bad\u7ec3topic\u4e3a10\u7684LSI\u6a21\u578b\uff0c\u5efa\u7acb\u7d22\u5f15\n",
      "        item_search.lsi = models.LsiModel(corpus_tfidf, id2word=item_search.dictionary, num_topics=10) \n",
      "        item_search.index = similarities.MatrixSimilarity(item_search.lsi[corpus],num_features=10)\n",
      "    \n",
      "    def search(self,srchstr,K=10):\n",
      "        ml_item=srchstr.partition('(')[0]\n",
      "        #print(ml_item)\n",
      "        texts_tokenized = [word.lower() for word in word_tokenize(ml_item)]  \n",
      "        english_stopwords = stopwords.words('english')\n",
      "        texts_filtered_stopwords = [word for word in texts_tokenized if not word in english_stopwords]\n",
      "        english_punctuations = [',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%']\n",
      "        texts_filtered = [word for word in texts_filtered_stopwords if not word in english_punctuations]\n",
      "\n",
      "        #\u8bcd\u5e72\u5316\n",
      "        ml_item = [item_search.st.stem(word) for word in texts_filtered]\n",
      "        #\u67e5\u8be2\u524dK\u4e2a\u6700\u76f8\u4f3c\u7684\n",
      "        #print(ml_item)\n",
      "        ml_bow = item_search.dictionary.doc2bow(ml_item)\n",
      "        ml_lsi = item_search.lsi[ml_bow]\n",
      "        sims = item_search.index[ml_lsi]\n",
      "        #print(sims)\n",
      "        sort_sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
      "        #print(sort_sims)\n",
      "        top=[]\n",
      "        idx=0\n",
      "        for i in sort_sims:\n",
      "            top.append(item_search.items.loc[i[0]][1])\n",
      "            idx+=1\n",
      "            if idx==K:\n",
      "                break\n",
      "        return top\n",
      "    \n",
      "if __name__ == \"__main__\": \n",
      "    item_s=item_search('u.item')\n",
      "    print(item_s.search('Four Rooms (1995) '))\n",
      "       "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Four Rooms (1995)', 'Room with a View, A (1986)', 'Roommates (1995)', 'Other Voices, Other Rooms (1997)', 'Event Horizon (1997)', 'All About Eve (1950)', 'For Ever Mozart (1996)', 'Getting Even with Dad (1994)', 'Daytrippers, The (1996)', 'Home Alone 3 (1997)']\n"
       ]
      }
     ],
     "prompt_number": 24
    }
   ],
   "metadata": {}
  }
 ]
}